{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7939715,"sourceType":"datasetVersion","datasetId":4667854}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport skimage as ski\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(img):\n    filtered_img      = ski.filters.median(img, mode = 'nearest')\n    gray_scaled_img   = ski.color.rgb2gray(filtered_img)\n\n    # Calculate the Otsu's threshold for the grayscale image\n    threshold = ski.filters.threshold_otsu(gray_scaled_img)\n\n    # Create a binary image by setting all pixels with a value less than the threshold to True (foreground) \n    # and others to False (background)\n    binary_img = gray_scaled_img < threshold\n\n    # Convert the binary image to an 8-bit unsigned integer format for further processing\n    # In this format, each pixel value ranges from 0 to 255, where 0 represents black and 255 represents white.\n    ubyte_img = img = ski.util.img_as_ubyte(binary_img)\n\n    # Calculate the number of black pixels in the ubyte image (pixels with a value of 0)\n    black_pixels = np.sum(ubyte_img == 0)\n\n    # Get the total number of pixels in the ubyte image\n    total_pixels = ubyte_img.size\n\n    # Calculate the percentage of black pixels in the image\n    percentage_black_pixels = (black_pixels / total_pixels) * 100\n\n    # If more than 50% of the pixels in the image are black\n    if percentage_black_pixels > 50:\n        # Invert the image colors (i.e., black becomes white and vice versa)\n        white_background_img = np.where(ubyte_img == 0, 255, 0)\n    else:\n        # If less than or equal to 50% of the pixels are black, keep the image as is\n        white_background_img = ubyte_img  \n\n    return white_background_img","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mimicing the idea of pagination, the following function will preprocess and save the images in batches, given a start index and a batch size\ndef preprocess_and_save_images(start_index = 0, batch_size = 1000):\n    Fonts  = [ 'IBM Plex Sans Arabic', 'Lemonada', 'Marhey','Scheherazade New'] \n\n    # Define the directory where the preprocessed images will be saved\n    base_save_dir = \"/kaggle/working/preprocessed_images_2\"\n\n    # Check if the base directory exists. If it doesn't, create a new directory with that name\n    if not os.path.exists(base_save_dir):\n        os.makedirs(base_save_dir)\n\n    for font in Fonts:\n        font_path = f\"/kaggle/input/fonts-dataset-cmp/fonts-dataset/{font}/*.jpeg\"\n        # Create a directory for the current font inside the base directory\n        font_save_dir = os.path.join(base_save_dir, font)\n        if not os.path.exists(font_save_dir):\n            os.makedirs(font_save_dir)\n\n        # Get all files in the font_path directory, sorted in ascending order\n        all_files = sorted(glob.glob(font_path))\n\n        # Determine the end index for processing\n        end_index = min(start_index + batch_size, len(all_files))\n\n        # Process only the files within the start and end indices\n        for i, filename in enumerate(tqdm(all_files[start_index:end_index], desc=f\"Processing {font}\")):\n            img = ski.io.imread(filename)\n            white_background_img = preprocess_image(img)          \n\n            # Save the processed image immediately\n            filename = os.path.join(font_save_dir, f\"{str(i + start_index).zfill(3)}.jpg\")\n            cv2.imwrite(filename, white_background_img)\n\n    print(\"Image preprocessing and saving completed.\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_images(start_index = 0, batch_size = 1000):\n    # Define the directory where the preprocessed images are stored\n    base_img_dir = \"/kaggle/working/preprocessed_images_2\"\n\n    # Retrieve the list of all font directories in the base directory\n    font_dirs = os.listdir(base_img_dir)\n\n    # Initialize two empty lists to store the image data and corresponding labels\n    x_data = []\n    y_data = []\n\n    # Iterate over each font directory\n    for font_dir in tqdm(font_dirs, desc=\"Loading fonts\"):\n        # Construct the full path for the current font directory\n        font_path = os.path.join(base_img_dir, font_dir)\n        # Retrieve the list of all image files in the current font directory\n        img_files = sorted(os.listdir(font_path))\n        # Calculate the end index for the current batch\n        end_index = start_index + batch_size\n\n        # Iterate over each image file in the current batch\n        for i in range(start_index, min(end_index, len(img_files))):\n            # Construct the full file path for the current image file\n            img_path = os.path.join(font_path, img_files[i])\n\n            # Read the image file as a grayscale image using OpenCV\n            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n\n            # Add the image data to the x_data list\n            x_data.append(img)\n\n            # Add the font name as the label to the y_data list\n            y_data.append(font_dir)\n\n    # Convert the lists of image data and labels to numpy arrays for easier manipulation\n    x_data = np.array(x_data)\n    y_data = np.array(y_data)\n\n    # Randomly shuffle the data and labels to ensure a good mix for training\n    p = np.random.permutation(len(x_data))\n    x_data = x_data[p]\n    y_data = y_data[p]\n\n    return x_data, y_data","metadata":{},"execution_count":null,"outputs":[]}]}